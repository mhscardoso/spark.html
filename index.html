<!DOCTYPE html>
<html lang="pt-BR">
<head>
	<meta charset="UTF-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Apache Spark - Grupo 05</title>
	<link rel="icon" type="image/x-icon" href="resources/spark-logo-rev.svg">
	<link href='https://fonts.googleapis.com/css?family=DM Sans' rel='stylesheet'>
	<link rel="stylesheet" href="style.css">
</head>
<body>

<header class="header">
	<div class="image">
		<img style="margin: 0;" src="resources/spark-logo-rev.svg" alt="" width="141" height="72">
	</div>
</header>

<main>

<nav class="nav">
	<ul class="my-ul">
		<div class="image-top">
			<img src="resources/linkedin-network.svg" width="90%">
			<h2 style="color: white;">Apache Spark</h2>
			<p>Redes de Computadores I - 24.1</p>
			<p>Grupo 05</p>
		</div>

		<li id="0."><a style="text-align: center;">Capa</a></li>
		<li id="1."><a>1. - Introdução</a></li>
			<li id="1.1."><a><p style="margin-left: 10pt;">1.1. - O que é o Apache Spark?</p></a></li>

				<li id="1.1.1."><a><p style="margin-left: 20pt;">1.1.1. - Definição de Processamento Distribuído</p></a></li>
				<li id="1.1.2."><a><p style="margin-left: 20pt;">1.1.2. - Importância no processamento de grandes volumes de dados</p></a></li>
		
			<li id="1.2."><a><p style="margin-left: 10pt;">1.2. - De início, com Apache Hadoop</p></a></li>
			<li id="1.3."><a><p style="margin-left: 10pt;">1.3. - Hadoop MapReduce</p></a></li>


		<li id="2."><a>2. - Gerenciamento Distribuído</a></li>

			<li id="2.1."><a><p style="margin-left: 10pt;">2.1. - De Hadoop MapReduce para Apache Spark</p></a></li>
			<li id="2.2."><a><p style="margin-left: 10pt;">2.2. - Directed Acyclic Graph (DAG)</p></a></li>


		<li id="3."><a>3. - Dados Distribuídos e Paralelização de Operações</a></li>

			<li id="3.1."><a><p style="margin-left: 10pt;">3.1. - Resilient Distributed Dataset (RDD)</p></a></li>
			<li id="3.2."><a><p style="margin-left: 10pt;">3.2. - Dataframes e Datasets</p></a></li>
			<li id="3.3."><a><p style="margin-left: 10pt;">3.3. - Variáveis Compartilhadas</p></a></li>
			<li id="3.4."><a><p style="margin-left: 10pt;">3.4. - Transformações e Ações</p></a></li>
			<li id="3.5."><a><p style="margin-left: 10pt;">3.5. - Arquitetura do Apache Spark</p></a></li>

		<li id="4."><a>4. - Aplicações com Apache Spark</a></li>

			<li id="4.1."><a><p style="margin-left: 10pt;">4.1. - Spark para Machine Learning</p></a></li>
			<li id="4.2."><a><p style="margin-left: 10pt;">4.2. - Spark para Processamento de Big Data</p></a></li>
			<li id="4.3."><a><p style="margin-left: 10pt;">4.3. - Spark para Processamento de Grafos</p></a></li>
			<li id="4.4."><a><p style="margin-left: 10pt;">4.4. - Spark para Processamento de Fluxo (Stream Processing), uma visão geral</p></a></li>

		<li id="5."><a>5. - Conclusões</a></li>

		<li id="6." style="margin-bottom: 20px;"><a>6. - Bibliografia</a></li>
	</ul>
</nav>

<div id="content">




<div id="capa">
	<h1 style="text-align: center; margin-left: 20%;">Apache Spark</h1>
	<h3>Redes de Computadores I - 24.1</h3>
	<h3>Trabalho desenvolvido pelos alunos da Universidade Federal do Rio de Janeiro:</h3>

	<ul>
		<li>Lucas Garcia Santiago de Abreu</li>
		<li>Matheus Henrique Sant'Anna Cardoso</li>
		<li>Vinícius Quintanilha Porto Gomes</li>
	</ul>
</div>




<div id="introducao">
	<h1>1. Introdução</h1>
	<p>
		A área de análise de <em>Big Data</em> é repleta de pesquisas e desafios. Ao longo dos anos, torna-se emergente
		a necessidade por inovações na área em diversos campos da indústria.
	</p>

	<p>
		Sendo assim, é essencial um framework desenhado especificamente para lidar com as requisições impostas por
		dados cada vez mais massivos para preencher as necessidades de velocidade, armazenamento e executar da melhor
		forma possível os algorítmos pelos quais essas imensas massas de dados serão submetidos.
	</p>

	<p>
		Dessa forma, o <em>Apache Spark</em> surge como uma ferramenta que introduziu uma nova abordagem para ciência
		e engenharia de dados, na qual um único motor (<em>engine</em>) é necessário podendo ser utilizado em diversas
		linguagens de alto nível, como Java, Python, SQL, entre outras.
	</p>

	<p>
		Essa versatilidade garantiu ao Spark uma plena adoção tanto na indústria quanto na academia e, hoje, é utilizada
		em projetos <em>open source</em> em algumas iniciativas da <em style="font-weight: bold;">Apache Sofware Foundation</em>.
	</p>

	<p>
		Dada a sua importância e às interessantes formas como esta ferramenta resolve alguns problemas da computação
		com soluções que incluem processamento distribuído e em memória, é crucial a abordagem dela em um curso atual
		de Redes de Computadores.
	</p>
</div>




<div id="o_que_e">
	<h1>1.1. O que é o Apache Spark?</h1>
	<p>
		Com o projeto sendo iniciado em 2009 por <a target="_blank" href="https://people.eecs.berkeley.edu/~matei/">
		Matei Zaharia</a>
		e, após ter sido doado para a Apache Software Foundation em 2013 (possuia a licença BSD
		desde 2010), vários pesquisadores contribuíram para com a ferramenta buscando a melhoria
		de seu núcleo (<em>core</em>) e suas bibliotecas de mais alto nível.
	</p>
	<p>
		Ao todo, o sistema do Apache Spark consistem em diversos componentes dos quais constam, além
		de seu próprio núcleo, várias bibliotecas de mais alto nível que permitem executar os algorítmos
		de aprendizado de máquina ou busca e mineração de dados.
	</p>
	<p>
		Dessas bibliotecas, podemos citar:
		<ul>
			<li>
				Spark's MLlib: Para aprendizado de máquina
			</li>
			<li>
				GraphX: Para análise de Grafos
			</li>
			<li>
				Spark Streaming: Para processamento de stream
			</li>
			<li>
				Spark SQL: Para processamento de dads estruturados
			</li>
		</ul>

		<div style="margin: auto; width: 50%;">
			<img src="resources/graphx.png" width="300" height="90">
			<img src="resources/spark_streaming.png" width="200" height="150">
			<img src="resources/spark_mlib.jpeg" width="200" height="150">
			<img src="resources/spark_aql.jpg" width="200" height="150">
		</div>
	</p>

	<p>
		Com um núcleo independente e tais bibliotecas já desenvolvidas por <q>debaixo dos panos</q>,
		o Spark mostra uma de duas vantagens que é a possibilidade do uso de diversas linguagens de
		programação de alto nível oferecendo uma interface simples para programação com pipelines de 
		dados em larga escala.
	</p>

	<p>
		A principal ferramenta está na forma em como o Spark lida com os dados, ou seja, a abstração
		feita para os dados, com a utilização dos Datasets Distribuídos, ou <em>Resilient Distributed 
		Datased</em> (RDD) sobre o qual falaremos mais a frente.
	</p>
</div>




<div id="definicao">
	<h1>1.1.1. Definição de Processamento Distribuído</h1>

	<p>
		É de suma importância que passemos pelo tópico de processamento distribuído ainda que seja apenas
		para definí-lo. Isso se dá pela sua relevância, não apenas na ferramenta em si da qual se trata
		este trabalho, mas do contexto de processamento de dados e <em>Big Data</em> como um todo. Sendo
		assim, uma breve síntese.
	</p>

	<p>
		O processamento distribuído é um paradigma de computação no qual tarefas computacionais são executadas em múltiplos dispositivos ou computadores interconectados em uma rede, chamados de nós.
		Logo, ao invés de depender de uma única máquina para o processamento de grandes volumes de dados,
		o trabalho é distribuído entre esses diversos nós permitindo a paralelização das operações.
	</p>

	<div class="centered-div">
		<img src="resources/dist_sistems.png" width="640" height="400" alt="Imagem ilustrativa">
		Fonte: <a target='_blank' href="https://www.techtarget.com/whatis/definition/distributed-computing">distributed computing</a> em TechTarget.
	</div>

	<p>
		Além disso, permite, por natureza, gerar um ecossistema mais tolerante a falhas por conta
		da redundância.
	</p>

	<p>
		Seu funcionamento pode se dar através de memória compartilhada, passagem de mensagem (ou ambos)
		em que, normalmente, um controlador central define tarefas para as diversas máquinas na rede que,
		trabalhando de forma independente, enviam o resultado final ao coordenador central, o qual combina
		os resultados e gera uma saída final.
	</p>

	<p>
		O objetivo do processamento distribuído é aumentar a capacidade de processamento e melhorar o desempenho geral, permitindo que grandes volumes de dados sejam processados de forma mais eficiente e rápida, além de gerar sistemas mais tolerantes à falhas.
	</p>
</div>

<div id="importancia">
	<h1>1.1.2. Importância no processamento de grandes volumes de dados</h1>
	<p>
		É sabido que a quantidade de dados no planeta avança a passos largos. Dentro de empresas, não
		é diferente. Nisso, para reduzir custos e otimizar decisões, o processamento de <em>Big Data</em>
		é fundamental.
	</p>

	<p>
		Já foi dito que o Apache Spark possui adoção na indústria e na academia. Isso se deve ao fato de
		ser necessária a análise de dados para políticas públicas e ciência de uma forma geral, seja em
		decifrar o código genético do coronavírus ou analisar as linhas de transporte de uma cidade, os
		dados estão em todos os campos.
	</p>
</div>




<div id="apache_hadoop">
	<h1>1.2. De início, com Apache Hadoop</h1>
	<p>
		O Apache Hadoop é um framework de código aberto projetado para o armazenamento e processamento
		distribuído de grandes volumes de dados em clusters de computadores. Utilizando modelos de 
		programação simples, ele permite que essas tarefas sejam realizadas de forma eficiente. O Hadoop é 
		escalável, podendo ser expandido de um único computador para milhares de máquinas em um cluster, com 
		cada uma delas fornecendo computação e armazenamento local. Dessa maneira, o Hadoop é capaz de 
		gerenciar e processar grandes conjuntos de dados, que podem variar de gigabytes a petabytes.
	</p>

	<p>
		O framework principal do Hadoop é composto por quatro módulos que, juntos, formam o ecossistema 
		Hadoop:
	</p>

	<ul>
		<li>
		<b>Hadoop Distributed File System (HDFS):</b> Sendo o componente central do ecossistema, o HDFS é um
		sistema de arquivos distribuído que permite acesso de alta capacidade aos dados do aplicativo, 
		sem a necessidade de definir esquemas antecipadamente.
		</li>

		<li>
		<b>Yet Another Resource Negotiator (YARN):</b> O YARN é uma plataforma de gerenciamento de
		recursos que
		coordena os recursos de computação em clusters e os utiliza para agendar os aplicativos dos
		usuários, realizando a programação e alocação de recursos em todo o sistema Hadoop.
		</li>

		<li>
		<b>Hadoop Common:</b> Inclui as bibliotecas e utilitários que são utilizados e compartilhados
		pelos demais
		módulos do Hadoop.
		</li>

		<li>
		<b>MapReduce:</b> Este é um modelo de programação voltado para o processamento de grandes volumes
		de dados.
		Utilizando algoritmos de computação distribuída e paralela, o MapReduce facilita a transferência da
		lógica de processamento, permitindo a criação de aplicativos que transformam grandes conjuntos de
		dados em conjuntos mais gerenciáveis.
		</li>
	</ul>

	<p>
		A plataforma funciona distribuindo jobs de big data e análise do Hadoop entre nós em um
		cluster de compute, dividindo-os em workloads menores que podem ser executados em paralelo.
	</p>

	<p>
		Todos os módulos do Hadoop são desenvolvidos com a premissa básica de que falhas de hardware 
		em máquinas individuais ou em racks de máquinas são eventos comuns e devem ser gerenciados
		automaticamente pelo framework de software.
	</p>

	<p>
		Claramente o MapReduce é o módulo mais atraente (pelo menos para os fins que estamos tratando aqui)
		para o quesito de análide de grandes volumes de dados. Não é a toa que é este o predecessor do
		Apache Spark.
	</p>


	<p>
		De forma geral, o Apache Hadoop já resolve algumas necessidades no quesito de <b>Sistemas
		Distribuídos</b>. Sua componente mais promissora com relação aos dados será mais discutida
		no próximo tópico.
	</p>

	<h3>Problemas com Apache Hadoop</h3>
	<p>
		No entanto, as arquiteturas Hadoop enfrentam diversos desafios, especialmente ao longo do tempo.
		O Hadoop pode ser excessivamente complexo, demandando recursos e conhecimento significativos para
		sua configuração, manutenção e atualizações. Além disso, é demorado e ineficiente devido às
		frequentes leituras e gravações necessárias para realizar cálculos.
	</p>

</div>




<div id="hadoop_mr">
	<h1>1.3. Hadoop MapReduce</h1>
	<p>A estrutura do Framework funciona da seguinte forma:</p>

	<ul>
		<li>
			<b>Divisão e distribuição dos dados:</b> os dados são divididos em blocos menores chamados de "splits".
			Cada split é então distribuído para os nós do cluster de computadores.
		</li>
		<li>
			<b>Fase de Map:</b> uma função definida pelo usuário chamada de função "map" é aplicada a cada split 
			de dados. Esta função produz uma lista de pares chave-valor intermediários.
		</li>
		<li>
			<b>Ordenação e Particionamento:</b> os pares chave-valor intermediários são particionados e agrupados
			com base na chave. Esses pares são ordenados para garantir que todas as ocorrências da mesma
			chave estejam agrupadas juntas.
		</li>
		<li>
			<b>Fase de Shuffle e Sort:</b> os pares chave-valor intermediários são transferidos entre os nós do
			cluster para que todos os valores associados à mesma chave estejam disponíveis em um único nó.
		</li>
		<li>
			<b>Fase de Reduce:</b> uma função definida pelo usuário chamada de função "reduce" é aplicada a cada
			chave única e à lista de valores associados a essa chave. Esta função pode realizar operações 
			de agregação, filtragem ou outras operações definidas pelo usuário.
		</li>
		<li>
			<b>Saída:</b> os resultados da redução são escritos em arquivos de saída.
		</li>
	</ul>

	<p>
		A questão aqui é que, após as operações, o MapReduce persiste os dados no disco, o que
		pode acarretar em perdas de performance significativas.
	</p>

	<p>
		Por mais que o processamento distribuído já paralelize as operações, é necessário que as decisões
		e os processos (como executar algorítmos de aprendizado de máquina) sejam mais eficazes
		dado uma grande quantidade de dados.
	</p>
</div>




<div id="gerenciamento_dist">
	<h1>2. Gerenciamento Distribuído</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
	</p>
</div>




<div id="hadoop_mr_spark">
	<h1>2.1 De Hadoop MapReduce para Apache Spark</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>




<div id="dag">
	<h1>2.2 Directed Acyclic Graph (DAG)</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>




<div id="dados_distribuidos">
	<h1>3. Dados Distribuídos e Paralelização de Operações</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>




<div id="rdd">
	<h1>3.1. Resilient Distributed Dataset (RDD)</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>




<div id="dataframes">
	<h1>3.2. Dataframes e Datasets</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>




<div id="variaveis_compartilhadas">
	<h1>3.3. Variáveis Compartilhadas</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>




<div id="transformacoes">
	<h1>3.4. Transformações e Ações</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>




<div id="arquitetura">
	<h1>3.5. Arquitetura do Apache Spark</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>




<div id="aplicacoes">
	<h1>4. Aplicações com Apache Spark</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>




<div id="machine_learning">
	<h1>4.1. Spark para Machine Learning</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>




<div id="big_data">
	<h1>4.2. Spark para Big Data</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>




<div id="grafos">
	<h1>4.3. Spark para Processamento de Grafos</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>




<div id="fluxo">
	<h1>4.4. Spark para Processamento de Fluxo (Stream Processing), uma visão geral</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>




<div id="conclusao">
	<h1>5. Conclusões</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>




<div id="bibliografia">
	<h1>6. Bibliografia</h1>
	<p>
		- Apache Spark: A Big Data Processing Engine<br>
	    11/2019<br>
	    Conference: 2019 2nd IEEE Middle East and North Africa COMMunications Conference (MENACOMM)
	</p>

	<p>
		<a target='_blank' href="https://medium.com/@amitjoshi7/spark-architecture-a-deep-dive-2480ef45f0be">- Spark Architecture: A Deep Dive</a><br>
	    06/2023<br>
	    Amit Joshi
	</p>

	<p>
		<a target='_blank' href='https://www.interviewbit.com/blog/apache-spark-architecture/'>- Apache Spark Architecture – Detailed Explanation</a><br>
	    01/2024
	</p>

	<p>
		<a target="_blank" href="https://granulate.io/blog/apache-spark-architecture-best-practices-alternatives/">
		- Apache Spark: Architecture, Best Practices, and Alternatives</a><br>
	    Omer Mesika
	</p>

	<p>
		<a target="_blank" href="https://www.analyticsvidhya.com/blog/2021/08/understand-the-internal-working-of-apache-spark/">- Understand The Internal Working of Apache Spark</a><br>
	    Dhanya Thailappan<br>
	    08/2021
	</p>

	<p>
		<a target="_blank" href="https://spark.apache.org/docs/latest/cluster-overview.html">- Cluster Mode Overview (Spark Docs)</a><br>
	    Spark Documentation
	</p>


	<p>
		- Big data analytics on Apache Spark<br>
	    10/2016<br>
	    Salloum, S., Dautov, R., Chen, X. et al. Big data analytics on Apache Spark. Int J Data 
	    Sci Anal 1, 145–164 (2016). https://doi.org/10.1007/s41060-016-0027-9
	</p>


	<p>
		<a target="_blank" href="https://managebi.com/2023/09/28/spark-cluster-no-docker/">- SPARK: 
		Criando Cluster com Docker</a><br>
	    09/2023<br>
	    Douglas S. Souza
	</p>

	<p>
		<a target="_blank" href="https://data-flair.training/blogs/dag-in-apache-spark/">- DAGs 
		Apache Spark</a>
	</p>

	<p>
		<a target="_blank" href="https://www.ibm.com/br-pt/topics/apache-spark">- Apache Spark (IBM)</a>
	</p>

	<p>
		<a target="_blank" href="https://cloud.google.com/learn/what-is-hadoop?hl=pt-br">- O que é 
		Apache Hadoop? (Google)</a>
	</p>

	<p>
		<a target="_blank" href="https://aws.amazon.com/pt/what-is/hadoop/">- O que é Hadoop (AWS)</a>
	</p>
</div>

</div>

</main>

<script type="text/javascript" src="script.js"></script>

</body>
</html>