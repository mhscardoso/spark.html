<!DOCTYPE html>
<html lang="pt-BR">
<head>
	<meta charset="UTF-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Apache Spark - Grupo 05</title>
	<link rel="icon" type="image/x-icon" href="resources/spark-logo-rev.svg">
	<link href='https://fonts.googleapis.com/css?family=DM Sans' rel='stylesheet'>
	<link rel="stylesheet" href="style.css">
</head>
<body>

<header class="header">
	<div class="image">
		<img style="margin: 0;" src="resources/spark-logo-rev.svg" alt="" width="141" height="72">
	</div>
</header>

<main>

<nav class="nav">
	<ul class="my-ul">
		<div class="image-top">
			<img src="resources/linkedin-network.svg" width="90%">
			<h2 style="color: white;">Apache Spark</h2>
			<p>Redes de Computadores I - 24.1</p>
			<p>Grupo 05</p>
		</div>

		<li id="0."><a style="text-align: center;">Capa</a></li>
		<li id="1."><a>1. - Introdução</a></li>
			<li id="1.1."><a><p style="margin-left: 10pt;">1.1. - O que é o Apache Spark?</p></a></li>

				<li id="1.1.1."><a><p style="margin-left: 20pt;">1.1.1. - Definição de Processamento Distribuído</p></a></li>
				<li id="1.1.2."><a><p style="margin-left: 20pt;">1.1.2. - Importância no processamento de grandes volumes de dados</p></a></li>
		
			<li id="1.2."><a><p style="margin-left: 10pt;">1.2. - De início, com Apache Hadoop</p></a></li>
			<li id="1.3."><a><p style="margin-left: 10pt;">1.3. - Hadoop MapReduce</p></a></li>


		<li id="2."><a>2. - Gerenciamento Distribuído</a></li>

			<li id="2.1."><a><p style="margin-left: 10pt;">2.1. - De Hadoop MapReduce para Apache Spark</p></a></li>
			<li id="2.2."><a><p style="margin-left: 10pt;">2.2. - Directed Acyclic Graph (DAG)</p></a></li>


		<li id="3."><a>3. - Dados Distribuídos e Paralelização de Operações</a></li>

			<li id="3.1."><a><p style="margin-left: 10pt;">3.1. - Resilient Distributed Dataset (RDD)</p></a></li>
			<li id="3.2."><a><p style="margin-left: 10pt;">3.2. - Dataframes e Datasets</p></a></li>
			<li id="3.3."><a><p style="margin-left: 10pt;">3.3. - Variáveis Compartilhadas</p></a></li>
			<li id="3.4."><a><p style="margin-left: 10pt;">3.4. - Transformações e Ações</p></a></li>
			<li id="3.5."><a><p style="margin-left: 10pt;">3.5. - Arquitetura do Apache Spark</p></a></li>

		<li id="4."><a>4. - Aplicações com Apache Spark</a></li>

			<li id="4.1."><a><p style="margin-left: 10pt;">4.1. - Spark para Machine Learning</p></a></li>
			<li id="4.2."><a><p style="margin-left: 10pt;">4.2. - Spark para Processamento de Big Data</p></a></li>
			<li id="4.3."><a><p style="margin-left: 10pt;">4.3. - Spark para Processamento de Grafos</p></a></li>
			<li id="4.4."><a><p style="margin-left: 10pt;">4.4. - Spark para Processamento de Fluxo (Stream Processing), uma visão geral</p></a></li>

		<li id="5."><a>5. - Conclusões</a></li>

		<li id="6." style="margin-bottom: 20px;"><a>6. - Bibliografia</a></li>
	</ul>
</nav>

<div id="content">

<div id="capa">
	<h1 style="text-align: center; margin-left: 20%;">Apache Spark</h1>
	<h3>Redes de Computadores I - 24.1</h3>
	<h3>Trabalho desenvolvido pelos alunos da Universidade Federal do Rio de Janeiro:</h3>

	<ul>
		<li>Lucas Garcia Santiago de Abreu</li>
		<li>Matheus Henrique Sant'Anna Cardoso</li>
		<li>Vinícius Quintanilha Porto Gomes</li>
	</ul>
</div>

<div id="introducao">
	<h1>1. Introdução</h1>
	<p>
		A área de análise de <em>Big Data</em> é repleta de pesquisas e desafios. Ao longo dos anos, torna-se emergente
		a necessidade por inovações na área em diversos campos da indústria.
	</p>

	<p>
		Sendo assim, é essencial um framework desenhado especificamente para lidar com as requisições impostas por
		dados cada vez mais massivos para preencher as necessidades de velocidade, armazenamento e executar da melhor
		forma possível os algorítmos pelos quais essas imensas massas de dados serão submetidos.
	</p>

	<p>
		Dessa forma, o <em>Apache Spark</em> surge como uma ferramenta que introduziu uma nova abordagem para ciência
		e engenharia de dados, na qual um único motor (<em>engine</em>) é necessário podendo ser utilizado em diversas
		linguagens de alto nível, como Java, Python, SQL, entre outras.
	</p>

	<p>
		Essa versatilidade garantiu ao Spark uma plena adoção tanto na indústria quanto na academia e, hoje, é utilizada
		em projetos <em>open source</em> em algumas iniciativas da <em style="font-weight: bold;">Apache Sofware Foundation</em>.
	</p>

	<p>
		Dada a sua importância e às interessantes formas como esta ferramenta resolve alguns problemas da computação
		com soluções que incluem processamento distribuído e em memória, é crucial a abordagem dela em um curso atual
		de Redes de Computadores.
	</p>
</div>

<div id="o_que_e">
	<h1>1.1. O que é o Apache Spark?</h1>
	<p>
		Com o projeto sendo iniciado em 2009 por <a target="_blank" href="https://people.eecs.berkeley.edu/~matei/">
		Matei Zaharia</a>
		e, após ter sido doado para a Apache Software Foundation em 2013 (possuia a licença BSD
		desde 2010), vários pesquisadores contribuíram para com a ferramenta buscando a melhoria
		de seu núcleo (<em>core</em>) e suas bibliotecas de mais alto nível.
	</p>
	<p>
		Ao todo, o sistema do Apache Spark consistem em diversos componentes dos quais constam, além
		de seu próprio núcleo, várias bibliotecas de mais alto nível que permitem executar os algorítmos
		de aprendizado de máquina ou busca e mineração de dados.
	</p>
	<p>
		Dessas bibliotecas, podemos citar:
		<ul>
			<li>
				Spark's MLlib: Para aprendizado de máquina
			</li>
			<li>
				GraphX: Para análise de Grafos
			</li>
			<li>
				Spark Streaming: Para processamento de stream
			</li>
			<li>
				Spark SQL: Para processamento de dads estruturados
			</li>
		</ul>

		<div style="margin: auto; width: 50%;">
			<img src="resources/graphx.png" width="300" height="90">
			<img src="resources/spark_streaming.png" width="200" height="150">
			<img src="resources/spark_mlib.jpeg" width="200" height="150">
			<img src="resources/spark_aql.jpg" width="200" height="150">
		</div>
	</p>

	<p>
		Com um núcleo independente e tais bibliotecas já desenvolvidas por <q>debaixo dos panos</q>,
		o Spark mostra uma de duas vantagens que é a possibilidade do uso de diversas linguagens de
		programação de alto nível oferecendo uma interface simples para programação com pipelines de 
		dados em larga escala.
	</p>

	<p>
		A principal ferramenta está na forma em como o Spark lida com os dados, ou seja, a abstração
		feita para os dados, com a utilização dos Datasets Distribuídos, ou <em>Resilient Distributed 
		Datased</em> (RDD) sobre o qual falaremos mais a frente.
	</p>
</div>

<div id="definicao">
	<h1>1.1.1. Definição de Processamento Distribuído</h1>

	<p>
		É de suma importância que passemos pelo tópico de processamento distribuído ainda que seja apenas
		para definí-lo. Isso se dá pela sua relevância, não apenas na ferramenta em si da qual se trata
		este trabalho, mas do contexto de processamento de dados e <em>Big Data</em> como um todo. Sendo
		assim, uma breve síntese.
	</p>

	<p>
		O processamento distribuído é um paradigma de computação no qual tarefas computacionais são executadas em múltiplos dispositivos ou computadores interconectados em uma rede, chamados de nós.
		O objetivo do processamento distribuído é aumentar a capacidade de processamento e melhorar o desempenho geral, permitindo que grandes volumes de dados sejam processados de forma mais eficiente e rápida.
	</p>
</div>

<div id="importancia">
	<h1>1.1.2. Importância no processamento de grandes volumes de dados</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>

<div id="apache_hadoop">
	<h1>1.2. De início, com Apache Hadoop</h1>
	<p>
		Antes do Apache Spark, uma das principais tecnologias utilizadas era o Apache Hadoop, que se baseava no paradigma de MapReduce para processar grandes conjuntos de dados em clusters distribuídos. Embora eficaz para muitos casos de uso, o MapReduce tinha limitações em relação à velocidade de processamento de dados iterativos e interativos, devido à necessidade de escrever e ler dados do disco repetidamente.
	</p>
</div>

<div id="hadoop_mr">
	<h1>1.3. Hadoop MapReduce</h1>
	<p>A estrutura do Framework funciona da seguinte forma:</p>
	<li>Divisão e distribuição dos dados: os dados são divididos em blocos menores chamados de "splits". Cada split é então distribuído para os nós do cluster de computadores.</li>
	<li>Fase de Map: uma função definida pelo usuário chamada de função "map" é aplicada a cada split de dados. Esta função produz uma lista de pares chave-valor intermediários.</li>
	<li>Ordenação e Particionamento: os pares chave-valor intermediários são particionados e agrupados com base na chave. Esses pares são ordenados para garantir que todas as ocorrências da mesma chave estejam agrupadas juntas.</li>
	<li>Fase de Shuffle e Sort: os pares chave-valor intermediários são transferidos entre os nós do cluster para que todos os valores associados à mesma chave estejam disponíveis em um único nó.</li>
	<li>Fase de Reduce: uma função definida pelo usuário chamada de função "reduce" é aplicada a cada chave única e à lista de valores associados a essa chave. Esta função pode realizar operações de agregação, filtragem ou outras operações definidas pelo usuário.</li>
	<li>Saída: os resultados da redução são escritos em arquivos de saída.</li>
</div>

<div id="gerenciamento_dist">
	<h1>2. Gerenciamento Distribuído</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>

<div id="hadoop_mr_spark">
	<h1>2.1 De Hadoop MapReduce para Apache Spark</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>

<div id="dag">
	<h1>2.2 Directed Acyclic Graph (DAG)</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>

<div id="dados_distribuidos">
	<h1>3. Dados Distribuídos e Paralelização de Operações</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>

<div id="rdd">
	<h1>3.1. Resilient Distributed Dataset (RDD)</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>

<div id="dataframes">
	<h1>3.2. Dataframes e Datasets</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>

<div id="variaveis_compartilhadas">
	<h1>3.3. Variáveis Compartilhadas</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>

<div id="transformacoes">
	<h1>3.4. Transformações e Ações</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>

<div id="arquitetura">
	<h1>3.5. Arquitetura do Apache Spark</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>

<div id="aplicacoes">
	<h1>4. Aplicações com Apache Spark</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>

<div id="machine_learning">
	<h1>4.1. Spark para Machine Learning</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>

<div id="big_data">
	<h1>4.2. Spark para Big Data</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>

<div id="grafos">
	<h1>4.3. Spark para Processamento de Grafos</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>

<div id="fluxo">
	<h1>4.4. Spark para Processamento de Fluxo (Stream Processing), uma visão geral</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>

<div id="conclusao">
	<h1>5. Conclusões</h1>
	<p>
	The standard Lorem Ipsum passage, used since the 1500s
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
</p>
</div>

<div id="bibliografia">
	<h1>6. Bibliografia</h1>
	<p>
		- Apache Spark: A Big Data Processing Engine<br>
	    11/2019<br>
	    Conference: 2019 2nd IEEE Middle East and North Africa COMMunications Conference (MENACOMM)
	</p>

	<p>
		<a target='_blank' href="https://medium.com/@amitjoshi7/spark-architecture-a-deep-dive-2480ef45f0be">- Spark Architecture: A Deep Dive</a><br>
	    06/2023<br>
	    Amit Joshi
	</p>

	<p>
		<a target='_blank' href='https://www.interviewbit.com/blog/apache-spark-architecture/'>- Apache Spark Architecture – Detailed Explanation</a><br>
	    01/2024
	</p>

	<p>
		<a target="_blank" href="https://granulate.io/blog/apache-spark-architecture-best-practices-alternatives/">
		- Apache Spark: Architecture, Best Practices, and Alternatives</a><br>
	    Omer Mesika
	</p>

	<p>
		<a target="_blank" href="https://www.analyticsvidhya.com/blog/2021/08/understand-the-internal-working-of-apache-spark/">- Understand The Internal Working of Apache Spark</a><br>
	    Dhanya Thailappan<br>
	    08/2021
	</p>

	<p>
		<a target="_blank" href="https://spark.apache.org/docs/latest/cluster-overview.html">- Cluster Mode Overview (Spark Docs)</a><br>
	    Spark Documentation
	</p>


	<p>
		- Big data analytics on Apache Spark<br>
	    10/2016<br>
	    Salloum, S., Dautov, R., Chen, X. et al. Big data analytics on Apache Spark. Int J Data Sci Anal 1, 145–164 (2016). https://doi.org/10.1007/s41060-016-0027-9
	</p>


	<p>
		<a target="_blank" href="https://managebi.com/2023/09/28/spark-cluster-no-docker/">- SPARK: Criando Cluster com Docker</a><br>
	    09/2023<br>
	    Douglas S. Souza
	</p>

	<p>
		<a target="_blank" href="https://data-flair.training/blogs/dag-in-apache-spark/">- DAGs Apache Spark</a>
	</p>

	<p>
		<a target="_blank" href="https://www.ibm.com/br-pt/topics/apache-spark">- Apache Spark -- IBM</a>
	</p>
</div>

</div>

</main>

<script type="text/javascript" src="script.js"></script>

</body>
</html>